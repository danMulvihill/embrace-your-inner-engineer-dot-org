<div class="container">
<h1>A Brief History of Comuter Languages <br>or How We Learned How to Talk to Machines</h1>

<p>A sampling of some of the most significant computer languages, 
and some relatively unknown ones thrown in to help make sense of historical trends and developments.</p>

<div class="merow mehead">
    <div class="mecols">Primal Languages</div>
    <div class="mecols">Functional</div>
    <div class="mecols">Procedural</div>
    <div class="mecols">Object-Oriented</div>
</div>
<div class="meeralabels">Ancient times (before 1970)</div>
<div class="merow">
    <div class="mecols">
        <ul class="melist">
            <li class="mehiddenlabels">Primal Languages</li>
            <li>Algorithms (800s)</li><li>Machine (1800s)</li>
            <li>Assembly (1940s)</li>
            <span class="nbsp"><li class="nbsp">&nbsp;</li><li class="nbsp">&nbsp;</li><li class="nbsp">&nbsp;</li><li class="nbsp">&nbsp;</li><li class="nbsp">&nbsp;</li></span>
            <li>&nbsp;<!--BCPL (1966)--></li>
        </ul>
    </div>
    <div class="mecols">
        <ul class="melist">
            <li class="mehiddenlabels">Functional Languages</li>
            <span class="nbsp"><li>&nbsp;</li><li>&nbsp;</li></span>
            <li>&nbsp;</li>
            <span class="nbsp"><li>&nbsp;</li></span>
            <li>Lisp (1958)</li>
            <span class="nbsp"><li>&nbsp;</li><li>&nbsp;</li><li>&nbsp;</li><li>&nbsp;</li></span>
        </ul>
    </div>
    <div class="mecols">
        <ul class="melist">
            <li class="mehiddenlabels">Procedural Languages</li>
            <span class="nbsp"><li class="nbsp">&nbsp;</li><li class="nbsp">&nbsp;</li></span>
            <li>A-0 (1952)</li>
            <li>FORTRAN (1954)</li>
            <li>ALGOL (1958)</li>
            <li>COBOL (1959)</li>
            <span class="nbsp"><li class="nbsp">&nbsp;</li></span>
            <li>BASIC (1964)</li><li>PL/I (1966)</li>
        </ul>
    </div>
    <div class="mecols">
        <ul class="melist">
            <li class="mehiddenlabels">OOP Languages</li>
            <span class="nbsp"><li class="nbsp">&nbsp;</li>
            <li>&nbsp;<li>&nbsp;</li><li>&nbsp;</li>
            <li>&nbsp;</li><li>&nbsp;</li>
            <li>&nbsp;</li><li>&nbsp;</li></span>
            <li>Simula (1964-67)</li>
        </ul>
    </div>
</div>
<div class="meeralabels">ASCII Internet era, or the Unix Epoch (1970-)</div>
<div class="merow">
    <div class="mecols">
        <ul class="melist">
            <li class="mehiddenlabels">Low Languages</li>
            <span class="nbsp"><li>&nbsp;</span>
            <li>C (1972)</li>
            <li>&nbsp;<!--shell (1974)--><span class="nbsp"><li>&nbsp;</li>
            <li>&nbsp;<li>&nbsp;</span><li>&nbsp;<!--bash (1989)-->
            <span class="nbsp"><li>&nbsp;</li></span>
            <span class="nbsp"><li>&nbsp;</li></span></ul></div>
    <div class="mecols">
        <ul class="melist">
            <li class="mehiddenlabels">Functional Languages</li>
            <span class="nbsp"><li class="nbsp">&nbsp;</li></span>
            <li>Prolog (1972)</li><li>Scheme (1975)</li>
            <span class="nbsp"><li class="nbsp">&nbsp;</li>
            <li class="nbsp">&nbsp;</li></span>
            <li>Erlang (1986)</li><span class="nbsp">
            <li>&nbsp;</li></span><li>Haskell (1990)</li>
            <span class="nbsp"><li>&nbsp;</li></span>
        </ul>
    </div>
    <div class="mecols">
        <ul class="melist">
            <li class="mehiddenlabels">Procedural Languages</li>
            <li>Pascal (1970)</li>
            <span class="nbsp"><li>&nbsp;</li><li>&nbsp;</li><li>&nbsp;</li><li>&nbsp;</li></span>
            <li>Perl 1-4 (1987)</li>
            <span class="nbsp"><li>&nbsp;</li><li>&nbsp;</li></span>
            <span class="nbsp"><li>&nbsp;</li></span>
        </ul>
    </div>
    <div class="mecols">
        <ul class="melist">
            <li class="mehiddenlabels">OOP Languages</li>
            <span class="nbsp"><li>&nbsp;</li></span>
            <li>Small-talk (1972)</li>
            <li>C&#43;&#43; (1979-83)</li>
            <li>Objective C (83)</li>
            <li>Object Pascal (85)</li>
            <span class="nbsp"><li>&nbsp;</li><li>&nbsp;</li></span>
            <li>Visual Basic (91)</li>
            <li>Python (1991)</li>
        </ul>
    </div>
</div>
<div class="meeralabels">WWW era (1992-)</div>
<div class="merow">
    <div class="mecols">
        <ul class="melist nbsp">
            <li>&nbsp;<li>&nbsp;<li>&nbsp;<li>&nbsp;<li>&nbsp;<li>&nbsp;
        </ul>
    </div>
    <div class="mecols">
        <ul class="melist">
            <li class="mehiddenlabels">Thinking Languages</li>
            <li>R (1993)</li><span class="nbsp"><li>&nbsp;</li>
            </span><li>Scala (2003)</li>
            <span class="nbsp"><li class="nbsp">&nbsp;</li></span>
            <li>Clojure (2007)</li>
            <span><li class="nbsp"><li class="nbsp">&nbsp;</li></span>
        </ul>
    </div>
    <div class="mecols">
        <ul class="melist">
            <li class="mehiddenlabels">Doing Languages</li>
            <li>PHP 1-4 (1995)</li>
            <span class="nbsp"><li>&nbsp;</li><li>&nbsp;</li><li>&nbsp;</li><li>&nbsp;<li>&nbsp;</li></span>
        </ul>
    </div>
    <div class="mecols">
        <ul class="melist">
            <li class="mehiddenlabels">OOP Languages</li>
            <li>Java (1992)</li>
            <li>JavaScript (1995)</li>
            <li>Ruby (1995)</li>
            <li>C# &amp; J# (2000-02)</li>
            <li>Go (2009)</li>
            <li>Swift (2014)</li>
        </ul>
    </div>
</div>
<h4>Machine Language</h4>
<p>Machines come in a variety of shapes and forms, but we don't talk to most of them and they generally do one thing: the task they are designed to do. 
    There are simple machines, like wheel barrows, ramps, and screws, and there are slightly more complicated machines, like motors, light detectors, radio signal receiver/transmitters,
    and machines that smash atoms together.
    Occasionally we come across machines that allow us to feed them information and they do what we ask them to do if we are very specific with our instructions.
</p>
<!--<img src="images/jacloom.jpg" class="img-rounded pull-right gap-left">-->
<p>One of the first machines that humans tried talking to was something known as the Jacquard loom, named after it's inventor, Joseph-Marie Jacquard. 
    In 1801, Jacquard built a weaving loom that allowed people to feed it a set of attached cards, known as pattern cards. 
    These cards were perforated, and the perforations directed rods and needles to operate at certain sequences to make different patterns. 
</p>
<p>In the 1840s, while the pattern cards and the new looms were transforming the textile industry,
 a young countess Augusta Ada King, better known as Ada Lovelace, wanted to figure out how to talk to 
 another machine, a massive mechanical calculator being built by her friend Charles Babbage. Babbage and Ada had figured out that this machine, 
    known as an analytical machine, would not only calculate numbers but could also be programmed to do other jobs as well, like composing music, 
    by feeding it the right instructions. 
    In essence, this is what separates a 'computer' from lessor machines - being able to follow instructions to do multiple tasks by changing the instructions or what we now call 'software'. 
    Unfortunately, Babage never finished building his analytical machine, so Ada was never able to test her program.
    
    <!--Ada's software however was not a series of on/off instructions fed to processors like in modern-day computers, but rather a series of instructions, 
    or algorithms, to give to a person to switch levers and turn gears. -->
</p>
<!--<p>For the next 150 years, that was the most sophisticated that ours conversations with machines had gotten. In a sense, it was a form of direct communication with machines. We told the machine, or rather parts of the machine, to either do something or don't do something. It doesn't seem like we would get very far with this type of communication,
 but by combining "do"/"don't do" instructions with several different parts of a machine, we can get pretty sophisticated with combining instructions. The pattern cards of the Jacquard loom, for example, created intricate designs on textiles that would be nearly impossible without them. This
 is actually still how we talked to machines, for the most part, but now we have mnemonics that hide us from the tedious process of telling each part of the machine to turn and off.
</p>
<h4>Algorithms</h4>
<p>To understand the importance of algorithms in our relationship with machines, we 
    need to go a little farther back in time, to the year 825 A.D. This was the year a formal approach of providing instructions to computers was outlined in a book entitled <i>Algoritmi de 
    numero Indorum</i> which directly
    translates to "Algoritmi on Indian numbers" but you may find on Wikipedia or related sources as "Al-Khwarizmi on the 
    Hindu Art of Reckoning" or "On the Calculations with Hindu Numerals." Algoritmi, or Al-Khwarizmi, was a Persian astronomer who 
    introduced the modern Western world to the numerical symbols we know as Arabic numerals, the Indian concept of Zero, and reintroduced 
    ancient Greek mathematics. Of the many refinements Algoritmi worked on was the idea that bears his name in a corrupted English form, the algorithm. 
</p>
    <p>An algorithm is a set of instructions that can be written down by one person and presented to another person, and if carried 
    out faithfully without thinking too hard, will yield the same results.
       For hundreds of years, algorithms were used for a variety of industries such as
    navigation and astronomy for making long tedious calculations. The poor people hired for making these calculations were known
    as computers, because that's what they did; they computed. 
</p>
<p>For centuries, hundreds, if not thousands, of human computers had contributed to the development of science and technology. A
 few of them even made well-known contributions. 
 One of them was Henreitta Swan Leavitt, who, in 1908, formulating something called the 'period-luminosity relationship' of a particular type of stars 
 known as Cepheid variables. 
 This discovery essentially made it possible to determine how far galaxies are from us, which led to the discovery of an expanding universe and the big bang.
</p>-->
<h4>Assembly Language</h4>
    <p>Around the 1940s, some of the first people working on computers realized that many of the steps they did over and over again can be classified and labeled with mnemonics, 
        simple 2 to 3 letter phrases to tell other computers, for example, to open a specific set of circuits in this or that array to print a letter "A" on a 
        paper tape, or move this number on to the processor's register so can be multiplied with another number. 
        These set of instructions in the form of mnemonics were the first computer languages (or more specifically assembly languages). 
        Thus, assembly languages were a series of mnemonics written by one person to direct other people. 
        They would in turn eventually worked out how to feed the instructions directly into the machines instead of other people.</p>

<p>Computers at the core, are surprising simple machines. 
    They have a component called a 'processor' and a component called the 'memory'. Everything else is 'peripheral'. 
    The memory holds two or more numbers until the processor needs them and the processor does nothing more then adds two numbers 
    together and return that 'processed' number back to memory. That's really all a computer does.</p>   
    <p>The processor doesn't really multiply numbers together. It adds the same number multiply times. 
    The processor doesn't subtract numbers, it uses an algorithm known as 1s complement to add numbers in a way that achieves the same results. 
    Computers can't read letters. They use numbers to identify letters and look them up in ASCII or Unicode charts. 
    Computers can't even recognize Arabic numerals. They can only count to one and start over. 
    That's why we use binary digits (0="off" and 1="on") to talk to them. We translate binary digits into the decimal numbers that we humans like to deal with, but a computer does not really count binary digits, either. It turns on and off electrical switches - complex patterns of electrical switches - and we interpret, or abstract, these patterns with binary numbers.
    With computers, we essentially trained machines to switch electrical circuits on and off in certian patterns and sequences that do everything from writing e-mail messages to finding sub-atomic particles in atom-smashing parties. These would actually be very tedious and mind-numbing activity that would drive people crazy if we trained humans to do it. A computer does it much faster without thinking or complaining.<!--Remember this the next time you blame your computer for making your life complicated. It's precise the other way around. Our lives were already complicated thanks to our oversized brains. We are making machines' lives more complicated. -->
</p>
<p><!--With the first computer languages fed into electronic computers in the 1940s, programmers wrote lines of code that directed the 'memory' to move stored data into the 'processor' to be processed and then moved it back to memory. We don't know precisely when the first assembly languages were used or even where the name 'assembly' came from partly because the first programmers didn't realize the impact their work would have on the world. They were just trying make their jobs easier. <!-- In all likelihood it was probably a woman, or a group of women, because the vast majority of human computers were women. In addition, much of it was done in secrecy and obscurity because there was a war at the time. -->Two of the most common tasks people were having machines do was deciphering enemy codes and calculating trajectories for dropping bombs from airplanes. One of the first recorded use of assembly comes from a 1951 book entitled <i>The Preparation for an Electronic Digital Computer</i> by Maurice Wilkes, David Wheeler and Stanley Gill.  These three authors were mathematicians who worked on one of the earliest electronic computers known as the EDSAC at the Cavendish Laboratory in Cambridge, England. This book describes how assembly languages were used on the EDSAC.
</p>
<!--<p>Machines, by the way, played a significant role in keeping Great Britain from being overtaken up by the Nazis. 
    In addition to EDSAC, there was another machine known as Colossus which was used to decipher enemy codes. 
    A mathematician by the name of Alan Turing created some of the algorithms that the human computers fed to Colossus, one of the first non-human computers. 
    To be fair though, the Nazis were using machines to try take over the world, but they were not too successful with their plan, fortunately.
</p>-->
<h4>Complied Languages</h4>

<p>One problem with talking to a computer directly with assembly languages is that you had to make your language specific to each processor in each computer. 
     
    Each time a new processor was invented, a new assembly language had to be made for it. 
    This process was made easier with mass production of interchangeable processors, but what made life easier for programmers was a language that 
    could be translated into many assembly languages or directly into machine language. The mechanism that made this possible was something called a compiler.
    <p>Various people began working on compilers in the 1950s and one of the first was Grace Murray Hopper, a mathematician and rare admiral in the 
        United States Navy. 
        During the war, Grace Hopper worked on a machine known as the Automatic Sequence Controlled Calculator at Harvard University to help calculate missile
         trajectories for the Navy. After the war, Hopper was hired by the first computer "start-up" originally called the Eckert-Mauchly Computer Corporation
          which was quickly sold to the much larger Remington-Rand corporation. 
          At Remington-Rand, Hopper developed one of the first compilers for the first commercially 
          available computer known as the UNIVAC. The UNIVAC made it's debut into public consciousness by correctly predicting that Dwight Eisenhower would soundly defeat 
          Adlai Stevenson in the 1952 presidential election, while most human prognosticators were claiming the race would be close. Compilers are what allows a programmer to use one computer language to talk to several processors.  
          Many of Hopper's ideas and methods were used to develop the COBOL language in 1959. 
</p>
<p>At about the same time, another mathematician named John Backus, led a team at IBM to develop another language called FORTRAN. FORTRAN was designed to work on 
    IBM's first line of true computers known as the 700/7000 series, a group of models the size of refrigerators and what became known as mainframe computers.
        (John Backus latter contributed to an international committee of programmers in Switzerland that created another important early language known as ALGOL.)
     
</p>
<p> 
    FORTRAN was well-suited for numeric calculations. It was marketed and packaged for academic purposes for accurate scientific calculations. 
    COBOL and ALGOL on the other were marketed for business needs. Business managers like to do things, or at least they like to tell other people what to do. 
    Likewise, they wanted their computers to do things for them. Thus they needed a language to tell the machine what to do: "Calculate the quarterly totals",
     "Print out a report", "Take my raw data and create a pie chart". 
     Other people, like scientists working at universities, often have different goals. 
     They don't want the computer to do things, but rather they want the computer to help them to reveal some hidden secrets of nature. 
     In this goal, the human feeds the computer some information, and the computer finds some patterns and reveals the secrets. 
     This distinction has led to two paths that computer languages had diverged early in their development. 
     One path, the way of COBOL and ALGOL, led to the "imperative" languages. Like imperative tense in human languages, 
     their primary goal is to tell the computer what do. The other path is "declarative", in which the human feeds the computer data, 
     and the computer tells the human what to do (at least that's goal). Likewise, this path, in addition to being the way of academic eggheads, 
     is also the path of those interested in artificial intelligence.
</p>

<h4>Functional Programming</h4>
<p>All of the languages mentioned so far (COBOL, FORTRAN, ALGOL) were developed by mathematicians, but they made it possible 
for non-mathematicians to learn programming, which helped lead to the development of a new discipline, computer
science. Though mathematical concepts remain an essentially part of programming, the development of imperative languages provides 'short-cuts' and 
greater degrees of abstraction. If programming had remained exclusively a sub-discipline of mathematics, humans may have only had 
 functional languages to talk to computers. 
 <p>The idea of functional programming predates electronic computers. It represents the mechanical implication of lambda
 calculus, a mathematical sub-discipline devised primarily by the Princeton University mathematician Alonzo Church in the 1930s,
  although the British mathematician Alan Turing independently hit on some of the same ideas 
 around the same time. Lambda calculus,
 and the hypothetical Turing Machine, developed from the futile attempt to answer the question "Can mathematics be reduced to an algorithm that can 
 solve every problem."  The answer that Church, Turing and others came up with is essentially no, but this futile attempt did at least provide some
 side benefits.  Turing proved that devices can be made that are capable of performing any conceivable mathematical computation if they can be fed algorithms.
  Church's Lambda calculus turned out to be a convenient way to talk to these machines.
<p>In functional programming, the function is king. Every language has functions, although not all functions are true functions. Most people think of 
functions as way of encapsulating code and setting that code aside into 'libraries' that can be called upon when needed. This idea is more accurately referred
to a procedure or sub-routine and they have existed since the first assembly languages. A true function, on the other hand, is more like what
 you may have learned about in calculus class.  A function takes a value or a set of values, like a number or set of numbers, does something to it,
and returns another value. The real power of functional programming comes in to play, however, when that value can be not only a number or a string but 
also another function, or group of functions, and functions can return functions. These ideas of functions passing in and out of other functions and a set of rules for defining values that can be passes into functions comes from lambda calculus.
<h4>Lisp</h4>
<p>One of the first languages to rely heavily on functional programming, and one of the oldest computer languages still in widespread use, is a language known 
    as Lisp.  Lisp has it's origins in a paper written by the mathematician John McCarthy in 1958 while he was at the Massachusetts Institute of 
    Technology (MIT). In this paper, McCarthy demonstrated that all you need to talk to machines was a few simple mathematical
    operators, a type of statement known as a conditional statement, and functions, specifically the type of functions identified in lambda calculus. 
    McCarthy had no intention of designing a programming language, but rather was attempting to conceptualize a more efficient Turing Machine. 
    Steve Russell, one of McCarthy's graduate students, read
    McCarthy's paper and realized that those functions can be converted in machine code. He used an 704 IBM mainframe computer
    and created the first Lisp compiler.
<h4>Scheme</h4>
<p> There are a couple of 'dialects' of Lisp that are worth noting. One of them is Scheme, a language, or Lisp dialect,
    invented at the MIT Artificial Intelligence (AI) Lab in the 1970s. Scheme was invented to give a Lisp a more 
    minimalist design, but introduced some new concepts, like lexical scope, that became widespread in other languages.
    One fan of Lisp was Brendan Eich, an employee at Netscape in the 1990s who originally planned
    on implementing a Scheme interpreter in the Netscape browser to manipulate HTML and provide interactivity to Web pages.
     His employers, however, were not too thrived with this idea so instead he invented a language that is, at its a core,
     a secret functional language using many features of Scheme, but cleverly hiding them with Java-like syntax and an architecture
      borrowed from another language known as Self. This language eventually became known as Javascript.
<h4>Clojure</h4>
<p>The application of a functional language in the Web browser may have led, directly or indirectly, to a renewed interest in Lisp and functional programming concepts.  Another dialect of Lisp is Clojure. Clojure was 
invented in 2007 by a programmer named Rich Hickey. Clojure's main advantage is that it is compiled 
into Java bytecode. This feature gives it an advantage that it could be used by Java's platform, the Java Virtual Machine (JVM).
 </p>
 <h4>Scala</h4>
 <p>A few years before Clojure was introduced, Martin Odersky, a professor at the Ecole Polytechnique in Lausanne, Switzerland, 
 created another functional language known as Scala in 2003. Scala was designed to deal with many of the same concerns as Clojure. Like Clojure, Scala
 was created to be used on the JVM and to provide functional language concepts to the wider world of Java programming. Unlike Clojure, however,
 it is even less of a pure functional language. It's considered a hybrid language that combines concepts of functional and object-orientated languages.</p> 

 <h4>The ultimate triumph of Lambda</h4>
 <p>The development of Scala and Clojure has been part of a recent trend of increasing popularity in functional language concepts and the combining of functional concepts with
    the more conventional imperative language environments. Java itself now includes lambda functions in the latest version (Java 8), which came out in 2014. 
    Other languages outside the JVM, have either included lambda functions as an after-thought or have been strong in functional concepts from the start. 
    Javascript, mentioned above, is one of those languages that included lambda functions from its birth.
    Another popular new computer language, Ruby, was also developed by a programmer with a profound interests in Lisp and Scheme.  Functional programming has become mainstream, merging with other concepts, like objects, to such an extent that it is becoming harder and harder to divide and classify languages.
So by the time you finish reading this, the above table may make sense for historical purposes only.</p>

 <!--Functional programming is more of a concept then a set of languages. Some languages are more functional then others</p>


<h4>To be continued...</h4>
<p>I covered about half the languages listed in the table here, but not really in chronological order nor not so much in the order of different paradigm classifications mentioned, 
but I have plan. Trust me. I will cover everything else in a part two some time in the future. I promise. If you have any questions, concerns, or comments,
please feel free to e-mail me at dmulvihill3@gmail.com.</p>-->

<h4>Some further reading</h4>
<p>David Alan Grier. 2007. <i>When Computers Were Human.</i> Princeton University Press.
<p>Charles Petzold. 2000. <i>Code.</i> Microsoft Press.
<p>Bruce A. Tate. 2010. <i>Seven Languages in Seven Weeks: A Pragmatic Guide to Learning Programming Languages.</i> Pragmatic Programmers, LLC.
</div>